{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dp5QPfWYia_k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functorch import make_functional, vmap, grad, jacrev\n",
    "import functools\n",
    "\n",
    "from pyDOE import lhs\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cpu\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device = ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tK5HlgtUigTf"
   },
   "outputs": [],
   "source": [
    "class Plain(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim , h_dim , out_dim):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.Linear( in_dim , h_dim )\n",
    "        self.act1 =nn.Sigmoid()\n",
    "        self.ln2 = nn.Linear( h_dim , out_dim , bias=False )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.ln1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.ln2(out)\n",
    "        return out\n",
    "\n",
    "def count_parameters(model, requires_grad = True):\n",
    "    \"\"\"Count trainable parameters for a nn.Module.\"\"\"\n",
    "    if requires_grad:\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_Res(func_params, X_inner, Rf_inner):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    grad2_f = (jacrev(grad(f)))(X_inner, func_params)\n",
    "    dudX2 = (torch.diagonal(grad2_f))\n",
    "    \n",
    "    laplace = (dudX2[0] + dudX2[1] + dudX2[2] + dudX2[3] + dudX2[4] + dudX2[5])\n",
    "    \n",
    "    loss_Res = laplace - Rf_inner\n",
    "\n",
    "    return loss_Res.flatten()\n",
    "\n",
    "\n",
    "def compute_loss_b(func_params, X_bd, U_bd):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    u_pred = f(X_bd, func_params)\n",
    "    loss_b = u_pred - U_bd\n",
    "        \n",
    "    return loss_b.flatten()\n",
    "\n",
    "def compute_loss_j(func_params, X_ij, Uj_ij):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    X_ij=X_ij.reshape(len(X_ij), 1)\n",
    "\n",
    "    ij_outer = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], 1.0+0.0*X_ij[0]), 0)\n",
    "    ij_inner = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], -1.0+0.0*X_ij[0]), 0)\n",
    "\n",
    "    u_ij_outer = f(ij_outer, func_params)\n",
    "    u_ij_inner = f(ij_inner, func_params)\n",
    "    \n",
    "    ij_pred = u_ij_outer - u_ij_inner\n",
    "    \n",
    "    loss_j = ij_pred - Uj_ij\n",
    "        \n",
    "    return loss_j.flatten()\n",
    "\n",
    "def compute_loss_normal_jump(func_params, X_ij, Unj_ij):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    X_ij=X_ij.reshape(len(X_ij), 1)\n",
    "    \n",
    "    ij_outer = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], 1.0+0.0*X_ij[0]), 0)\n",
    "    ij_inner = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], -1.0+0.0*X_ij[0]), 0)\n",
    "\n",
    "    grad_f_outer = (grad(f))(ij_outer, func_params)\n",
    "    df_outer = (grad_f_outer)\n",
    "    Normal_outer = (df_outer[0]*X_ij[0]+df_outer[1]*X_ij[1]+df_outer[2]*X_ij[2]+df_outer[3]*X_ij[3]+df_outer[4]*X_ij[4]+df_outer[5]*X_ij[5])/torch.sqrt(X_ij[0]**2+X_ij[1]**2+X_ij[2]**2+X_ij[3]**2+X_ij[4]**2+X_ij[5]**2)\n",
    "    grad_f_inner = (grad(f))(ij_inner, func_params)\n",
    "    df_inner = (grad_f_inner)\n",
    "    Normal_inner = (df_inner[0]*X_ij[0]+df_inner[1]*X_ij[1]+df_inner[2]*X_ij[2]+df_inner[3]*X_ij[3]+df_inner[4]*X_ij[4]+df_inner[5]*X_ij[5])/torch.sqrt(X_ij[0]**2+X_ij[1]**2+X_ij[2]**2+X_ij[3]**2+X_ij[4]**2+X_ij[5]**2)\n",
    "    \n",
    "    normal_jump_pred = 1.0e-3*Normal_outer - Normal_inner\n",
    "\n",
    "    loss_normal_jump = normal_jump_pred - Unj_ij\n",
    "        \n",
    "    return loss_normal_jump.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wxr5Jd6B6nPE"
   },
   "outputs": [],
   "source": [
    "def exact_u(X):\n",
    "  z = X[:, 6:7]\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  u1 = np.sin(X[:,0:1])*np.sin(X[:,1:2])*np.sin(X[:,2:3])*np.sin(X[:,3:4])*np.sin(X[:,4:5])*np.sin(X[:,5:6])\n",
    "  # if z=-1 -> fn1\n",
    "  un1 = np.exp(X[:,0:1]+X[:,1:2]+X[:,2:3]+X[:,3:4]+X[:,4:5]+X[:,5:6])\n",
    "  eu = u1*(z+1.0)/2.0 + un1*(1.0-z)/2.0\n",
    "  return eu\n",
    "\n",
    "def rhs_f(X_inner):\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  f1 = -6.0*np.sin(X_inner[:,0:1])*np.sin(X_inner[:,1:2])*np.sin(X_inner[:,2:3])*np.sin(X_inner[:,3:4])*np.sin(X_inner[:,4:5])*np.sin(X_inner[:,5:6])\n",
    "  # if z=-1 -> fn1\n",
    "  fn1 = 6.0*np.exp(X_inner[:,0:1]+X_inner[:,1:2]+X_inner[:,2:3]+X_inner[:,3:4]+X_inner[:,4:5]+X_inner[:,5:6])\n",
    "  rf = f1*(X_inner[:,6:7]+1.0)/2.0 + fn1*(1.0-X_inner[:,6:7])/2.0\n",
    "  return rf\n",
    "\n",
    "def normal_u(X):\n",
    "  x = X[:, 0:10]\n",
    "  z = X[:, 10]\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  u1 = (X[:,0]*X[:,1])*(X[:,0]**8 + X[:,1]**8) + (X[:,2]*X[:,3])*(X[:,2]**8 + X[:,3]**8) + X[:,4]*X[:,5]*(X[:,4]**8 + X[:,5]**8) + X[:,6]*X[:,7]*(X[:,6]**8 +X[:,7]**8) + X[:,8]*X[:,9]*(X[:,8]**8+X[:,9]**8)\n",
    "  u1 = u1/np.sqrt(x**2 + y**2)\n",
    "  # if z=-1 -> fn1\n",
    "  un1 = (x+y)*np.exp(x+y)\n",
    "  un1 = un1/np.sqrt(x**2 + y**2)\n",
    "  nu = u1*(z+1.0)/2.0 + un1*(1.0-z)/2.0\n",
    "  return nu\n",
    "\n",
    "def normal_u(x0, x1, x2, x3, x4, x5, z):\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  u1 = np.cos(x0)*np.sin(x1)*np.sin(x2)*np.sin(x3)*np.sin(x4)*np.sin(x5)*x0\\\n",
    "  +np.sin(x0)*np.cos(x1)*np.sin(x2)*np.sin(x3)*np.sin(x4)*np.sin(x5)*x1\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.cos(x2)*np.sin(x3)*np.sin(x4)*np.sin(x5)*x2\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.sin(x2)*np.cos(x3)*np.sin(x4)*np.sin(x5)*x3\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.sin(x2)*np.sin(x3)*np.cos(x4)*np.sin(x5)*x4\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.sin(x2)*np.sin(x3)*np.sin(x4)*np.cos(x5)*x5\n",
    "  dist = np.sqrt(x0**2 + x1**2 + x2**2+x3**2 + x4**2 + x5**2)\n",
    "  u1 = u1/dist\n",
    "  # if z=-1 -> fn1\n",
    "  un1 = (x0+x1+x2+x3+x4+x5)*np.exp(x0+x1+x2+x3+x4+x5)\n",
    "  un1 = un1/dist\n",
    "  nu = u1*(z+1.0)/2.0 + un1*(1.0-z)/2.0\n",
    "  return nu\n",
    "\n",
    "def sign_x(X):\n",
    "  z = 0.0*X[:,0:1] + 1.0\n",
    "  for i in range(len(z)):\n",
    "    dist = np.linalg.norm(X[i,:], 2)\n",
    "    if dist < 0.5:\n",
    "      z[i] = -1.0\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXmSiyPzRr-R",
    "outputId": "278316dc-4b69-48a3-fc27-e6c39a3f2024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of inner points:  (100, 7)\n",
      "Size of boundary points:  (141, 7)\n",
      "Size of interface points:  (141, 6)\n"
     ]
    }
   ],
   "source": [
    "d = 6\n",
    "\n",
    "# number of grid points\n",
    "N_inner = 100\n",
    "N_bd = 141\n",
    "N_ij = 141\n",
    "\n",
    "# Training points\n",
    "\n",
    "## X_inner: points inside the domain, totally (N_inner-1)**2 points\n",
    "para_inner = lhs(d, N_inner)\n",
    "r = np.sqrt(para_inner[:,0:1]*0.36)\n",
    "t1 = para_inner[:,1:2]*np.pi\n",
    "t2 = para_inner[:,2:3]*np.pi\n",
    "t3 = para_inner[:,3:4]*np.pi\n",
    "t4 = para_inner[:,4:5]*np.pi\n",
    "t5 = para_inner[:,5:6]*2.0*np.pi\n",
    "X_inner = 0.0*para_inner\n",
    "X_inner[:, 0:1] = r*np.cos(t1)\n",
    "X_inner[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_inner[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_inner[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_inner[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_inner[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "z_inner = sign_x(X_inner)\n",
    "X_inner = np.hstack([X_inner, z_inner])\n",
    "Rf_inner = rhs_f(X_inner)\n",
    "Rf_inner = Rf_inner.reshape(N_inner, 1)\n",
    "\n",
    "## X_bd: points at the boundary, totally N_bd points\n",
    "para_bd = lhs(d, N_bd)\n",
    "r = 0.6\n",
    "t1 = para_bd[:,1:2]*np.pi\n",
    "t2 = para_bd[:,2:3]*np.pi\n",
    "t3 = para_bd[:,3:4]*np.pi\n",
    "t4 = para_bd[:,4:5]*np.pi\n",
    "t5 = para_bd[:,5:6]*2.0*np.pi\n",
    "X_bd = 0.0*para_bd\n",
    "X_bd[:, 0:1] = r*np.cos(t1)\n",
    "X_bd[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_bd[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_bd[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_bd[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_bd[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "X_bd = np.hstack([X_bd, 0.0*X_bd[:,0:1]+1.0])\n",
    "\n",
    "## U_bd: function values at the boundary, totally 2*d*N_bd points\n",
    "U_bd = exact_u(X_bd)\n",
    "U_bd = U_bd.reshape(N_bd, 1)\n",
    "\n",
    "## X_ij: points at the interior interface, totally N_ij points\n",
    "para_ij = lhs(d, N_bd)\n",
    "r = 0.5\n",
    "t1 = para_ij[:,1:2]*np.pi\n",
    "t2 = para_ij[:,2:3]*np.pi\n",
    "t3 = para_ij[:,3:4]*np.pi\n",
    "t4 = para_ij[:,4:5]*np.pi\n",
    "t5 = para_ij[:,5:6]*2.0*np.pi\n",
    "X_ij = 0.0*para_ij\n",
    "X_ij[:, 0:1] = r*np.cos(t1)\n",
    "X_ij[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_ij[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_ij[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_ij[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_ij[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "\n",
    "## Uj_ij: function jump at the interior interface, totally 2*d*N_bd points\n",
    "Uj_ij = exact_u(np.hstack([X_ij, 0.0*X_ij[:,0:1]+1.0])) - exact_u(np.hstack([X_ij, 0.0*X_ij[:,0:1]-1.0]))\n",
    "Uj_ij = Uj_ij.reshape(N_ij, 1)\n",
    "\n",
    "# beta_plus\n",
    "beta_plus = 1.0e-3\n",
    "## Unj_ij: normal jump at the interior interface, totally N_bd points\n",
    "Unj_ij = beta_plus*normal_u(X_ij[:,0:1], X_ij[:,1:2], X_ij[:,2:3], X_ij[:,3:4], X_ij[:,4:5], X_ij[:,5:6], 0.0*X_ij[:,0:1]+1.0)\\\n",
    "- normal_u(X_ij[:,0:1], X_ij[:,1:2], X_ij[:,2:3], X_ij[:,3:4], X_ij[:,4:5], X_ij[:,5:6], 0.0*X_ij[:,0:1]-1.0)\n",
    "\n",
    "print('Size of inner points: ', X_inner.shape)\n",
    "print('Size of boundary points: ', X_bd.shape)\n",
    "print('Size of interface points: ', X_ij.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bd_torch = torch.from_numpy(X_bd).requires_grad_(True).double().to(device)\n",
    "U_bd_torch = torch.from_numpy(U_bd).double().to(device)\n",
    "X_inner_torch = torch.from_numpy(X_inner).requires_grad_(True).double().to(device)\n",
    "Rf_inner_torch = torch.from_numpy(Rf_inner).double().to(device)\n",
    "X_ij_torch = torch.from_numpy(X_ij).requires_grad_(True).double().to(device)\n",
    "Uj_ij_torch = torch.from_numpy(Uj_ij).double().to(device)\n",
    "Unj_ij_torch = torch.from_numpy(Unj_ij).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain(\n",
      "  (ln1): Linear(in_features=7, out_features=10, bias=True)\n",
      "  (act1): Sigmoid()\n",
      "  (ln2): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n",
      "Number of paramters: 90\n"
     ]
    }
   ],
   "source": [
    "# single-layer model\n",
    "model = Plain(7, 10, 1).to(device)\n",
    "print(model)\n",
    "\n",
    "print(f\"Number of paramters: {count_parameters(model)}\")\n",
    "\n",
    "# Make model a functional\n",
    "func_model, func_params = make_functional(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aChmjTLTRsNt",
    "outputId": "385c417f-97dc-4b20-b21a-109611035f2c"
   },
   "outputs": [],
   "source": [
    "LM_iter = 3000\n",
    "mu_update = 2 # update \\mu every mu_update iterations\n",
    "div_factor = 1.3 # \\mu <- \\mu/div_factor when loss decreases\n",
    "mul_factor = 3 # \\mu <- mul_factor*\\mu when loss incerases\n",
    "\n",
    "mu = 10**5\n",
    "loss_sum_old = 10**5\n",
    "itera = 0\n",
    "\n",
    "savedloss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "2W4aJaHjwUKd",
    "outputId": "e06087e0-0b22-4fdd-a789-06442a3b1a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1, Loss_Res: 3.50068e+01, mu: 7.69231e+04\n",
      "Iter 501, Loss_Res: 3.89762e-10, mu: 3.47610e-07\n",
      "Iter 1001, Loss_Res: 3.31817e-10, mu: 2.66904e-07\n",
      "Iter 1501, Loss_Res: 3.29850e-10, mu: 2.04936e-07\n",
      "Iter 2001, Loss_Res: 3.28264e-10, mu: 1.57355e-07\n",
      "Iter 2501, Loss_Res: 3.26658e-10, mu: 1.20822e-07\n",
      "Iter 3001, Loss_Res: 3.24656e-10, mu: 9.27700e-08\n",
      "CPU times: user 3min 36s, sys: 8.98 s, total: 3min 45s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for step in range(LM_iter+1):\n",
    "    # Put into loss functional to get L_vec\n",
    "    L_vec_res = vmap(compute_loss_Res, (None, 0, 0))(func_params, X_inner_torch, Rf_inner_torch)\n",
    "    L_vec_b = vmap(compute_loss_b, (None, 0, 0))(func_params, X_bd_torch, U_bd_torch)\n",
    "    L_vec_j = vmap(compute_loss_j, (None, 0, 0))(func_params, X_ij_torch, Uj_ij_torch)\n",
    "    L_vec_nj = vmap(compute_loss_normal_jump, (None, 0, 0))(func_params, X_ij_torch, Unj_ij_torch)\n",
    "\n",
    "    L_vec_res = L_vec_res/np.sqrt(N_inner)\n",
    "    L_vec_b = L_vec_b/np.sqrt(N_bd)\n",
    "    L_vec_j = L_vec_j/np.sqrt(N_ij)\n",
    "    L_vec_nj = L_vec_nj/np.sqrt(N_ij)\n",
    "    loss = torch.sum(L_vec_res**2) + torch.sum(L_vec_b**2) + torch.sum(L_vec_j**2) + torch.sum(L_vec_nj**2)\n",
    "\n",
    "    # Consturct J for domain points\n",
    "    # (None, 0 ,0): func_params: no batch. data_d: batch wrt shape[0] (data[i, :]). force_value: batch wrt shape[0] (force_value[i,:])\n",
    "    \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_Res), (None, 0, 0))(func_params, X_inner_torch, Rf_inner_torch)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_res = g.view(len(g), -1) if cnt == 0 else torch.hstack([J_d_res, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "    \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_b), (None, 0, 0))(func_params, X_bd_torch, U_bd_torch)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_b = g.view(len(g), -1) if cnt == 0 else torch.hstack([J_d_b, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "        \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_j), (None, 0, 0))(func_params, X_ij_torch, Uj_ij_torch)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_j = g.view(len(g), -1) if cnt == 0 else torch.hstack([J_d_j, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "        \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_normal_jump), (None, 0, 0))(func_params, X_ij_torch, Unj_ij_torch)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_nj = g.contiguous().view(len(g), -1) if cnt == 0 else torch.hstack([J_d_nj, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "\n",
    "    # cat J_d and J_b into J\n",
    "    J_mat = torch.cat((J_d_res, J_d_b, J_d_j, J_d_nj))\n",
    "    L_vec = torch.cat((L_vec_res, L_vec_b, L_vec_j, L_vec_nj))\n",
    "\n",
    "    # update lambda\n",
    "    I = torch.eye((J_mat.shape[1])).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        J_product = J_mat.t()@J_mat\n",
    "        rhs = -J_mat.t()@L_vec\n",
    "        with torch.no_grad():\n",
    "            dp = torch.linalg.solve(J_product + mu*I, rhs)\n",
    "\n",
    "        # update parameters\n",
    "        cnt=0\n",
    "        for p in func_params:\n",
    "            mm=torch.Tensor([p.shape]).tolist()[0]\n",
    "            num=int(functools.reduce(lambda x,y:x*y,mm,1))\n",
    "            p+=dp[cnt:cnt+num].reshape(p.shape)\n",
    "            cnt+=num\n",
    "\n",
    "        itera += 1\n",
    "        \n",
    "        savedloss.append(loss.item())\n",
    "        \n",
    "        if step % mu_update == 0:\n",
    "            #if loss_sum_check < loss_sum_old:\n",
    "            if loss < loss_sum_old:\n",
    "                mu = max(mu/div_factor, 10**(-9))\n",
    "            else:\n",
    "                mu = min(mul_factor*mu, 10**(8))\n",
    "            loss_sum_old = loss\n",
    "                \n",
    "        if step%500 == 0:\n",
    "            print(\n",
    "                    'Iter %d, Loss_Res: %.5e, mu: %.5e' % (itera, loss.item(), mu)\n",
    "                )\n",
    "            \n",
    "        if step == LM_iter or loss.item()<10**(-12):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = 0\n",
    "end = itera\n",
    "idx = list(range(start, end, 1))\n",
    "\n",
    "fig = plt.figure(figsize= (10, 10))\n",
    "plt.ylim(10**(-13), 10**(2))\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.plot(idx, savedloss[start:end], label = \"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQTHAR0ARsQN",
    "outputId": "3f07fa0b-7388-4eb4-acd0-2308c080d7c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error u (relative inf-norm): 4.922615e-05\n",
      "Error u (relative 2-norm): 7.120056e-06\n",
      "Error u (absolute inf-norm): 1.627561e-04\n",
      "Error u (absolute 2-norm): 6.705199e-06\n"
     ]
    }
   ],
   "source": [
    "N_test = 200000\n",
    "\n",
    "para_test = lhs(d, N_test)\n",
    "r = np.sqrt(para_test[:,0:1]*0.36)\n",
    "t1 = para_test[:,1:2]*np.pi\n",
    "t2 = para_test[:,2:3]*np.pi\n",
    "t3 = para_test[:,3:4]*np.pi\n",
    "t4 = para_test[:,4:5]*np.pi\n",
    "t5 = para_test[:,5:6]*2.0*np.pi\n",
    "X_test = 0.0*para_test\n",
    "X_test[:, 0:1] = r*np.cos(t1)\n",
    "X_test[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_test[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_test[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_test[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_test[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "z_test = sign_x(X_test)\n",
    "X_test = np.hstack([X_test, z_test])\n",
    "\n",
    "u_test = exact_u(X_test)\n",
    "u_test = u_test.reshape((N_test,1))\n",
    "\n",
    "X_test_torch = torch.tensor(X_test).double().to(device)\n",
    "u_pred = func_model(func_params, X_test_torch).detach().cpu().numpy()\n",
    "\n",
    "error = np.absolute(u_pred - u_test)\n",
    "\n",
    "error_u_inf_r = np.linalg.norm(error, np.inf)/np.linalg.norm(u_test, np.inf)\n",
    "print('Error u (relative inf-norm): %e' % (error_u_inf_r))\n",
    "error_u_2r = np.linalg.norm(error,2)/np.linalg.norm(u_test,2)\n",
    "print('Error u (relative 2-norm): %e' % (error_u_2r))\n",
    "error_u_inf = np.linalg.norm(error, np.inf)\n",
    "print('Error u (absolute inf-norm): %e' % (error_u_inf))\n",
    "error_u_2 = np.linalg.norm(error,2)/np.sqrt(N_test)\n",
    "print('Error u (absolute 2-norm): %e' % (error_u_2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SINet_poisson_6D_sphe_sphe_double.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
