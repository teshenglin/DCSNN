{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Dp5QPfWYia_k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from functorch import make_functional, vmap, grad, jacrev\n",
    "import functools\n",
    "\n",
    "from pyDOE import lhs\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tK5HlgtUigTf"
   },
   "outputs": [],
   "source": [
    "class Plain(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim , h_dim , out_dim):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.Linear( in_dim , h_dim )\n",
    "        self.act1 =nn.Sigmoid()\n",
    "        self.ln2 = nn.Linear( h_dim , out_dim , bias=False )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.ln1(x)\n",
    "        out = self.act1(out)\n",
    "        out = self.ln2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_Res(func_params, X_inner, Rf_inner):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    grad2_f = (jacrev(grad(f)))(X_inner, func_params)\n",
    "    dudX2 = (torch.diagonal(grad2_f))\n",
    "    \n",
    "    laplace = (dudX2[0] + dudX2[1] + dudX2[2] + dudX2[3] + dudX2[4] + dudX2[5])\n",
    "    \n",
    "    loss_Res = laplace - Rf_inner\n",
    "\n",
    "    return loss_Res.flatten()\n",
    "\n",
    "\n",
    "def compute_loss_b(func_params, X_bd, U_bd):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    u_pred = f(X_bd, func_params)\n",
    "    loss_b = u_pred - U_bd\n",
    "        \n",
    "    return loss_b.flatten()\n",
    "\n",
    "def compute_loss_j(func_params, X_ij, Uj_ij):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    X_ij=X_ij.reshape(len(X_ij), 1)\n",
    "\n",
    "    ij_outer = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], 1.0+0.0*X_ij[0]), 0)\n",
    "    ij_inner = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], -1.0+0.0*X_ij[0]), 0)\n",
    "\n",
    "    u_ij_outer = f(ij_outer, func_params)\n",
    "    u_ij_inner = f(ij_inner, func_params)\n",
    "    \n",
    "    ij_pred = u_ij_outer - u_ij_inner\n",
    "    \n",
    "    loss_j = ij_pred - Uj_ij\n",
    "        \n",
    "    return loss_j.flatten()\n",
    "\n",
    "def compute_loss_normal_jump(func_params, X_ij, Unj_ij):\n",
    "\n",
    "    def f(x, func_params):\n",
    "        output = func_model(func_params, x)\n",
    "        return output.squeeze(0)\n",
    "    \n",
    "    X_ij=X_ij.reshape(len(X_ij), 1)\n",
    "    \n",
    "    ij_outer = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], 1.0+0.0*X_ij[0]), 0)\n",
    "    ij_inner = torch.cat((X_ij[0], X_ij[1], X_ij[2], X_ij[3], X_ij[4], X_ij[5], -1.0+0.0*X_ij[0]), 0)\n",
    "\n",
    "    grad_f_outer = (grad(f))(ij_outer, func_params)\n",
    "    df_outer = (grad_f_outer)\n",
    "    Normal_outer = (df_outer[0]*X_ij[0]+df_outer[1]*X_ij[1]+df_outer[2]*X_ij[2]+df_outer[3]*X_ij[3]+df_outer[4]*X_ij[4]+df_outer[5]*X_ij[5])/torch.sqrt(X_ij[0]**2+X_ij[1]**2+X_ij[2]**2+X_ij[3]**2+X_ij[4]**2+X_ij[5]**2)\n",
    "    grad_f_inner = (grad(f))(ij_inner, func_params)\n",
    "    df_inner = (grad_f_inner)\n",
    "    Normal_inner = (df_inner[0]*X_ij[0]+df_inner[1]*X_ij[1]+df_inner[2]*X_ij[2]+df_inner[3]*X_ij[3]+df_inner[4]*X_ij[4]+df_inner[5]*X_ij[5])/torch.sqrt(X_ij[0]**2+X_ij[1]**2+X_ij[2]**2+X_ij[3]**2+X_ij[4]**2+X_ij[5]**2)\n",
    "    \n",
    "    normal_jump_pred = 1.0e-3*Normal_outer - Normal_inner\n",
    "\n",
    "    loss_normal_jump = normal_jump_pred - Unj_ij\n",
    "        \n",
    "    return loss_normal_jump.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Wxr5Jd6B6nPE"
   },
   "outputs": [],
   "source": [
    "def exact_u(X):\n",
    "  z = X[:, 6:7]\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  u1 = np.sin(X[:,0:1])*np.sin(X[:,1:2])*np.sin(X[:,2:3])*np.sin(X[:,3:4])*np.sin(X[:,4:5])*np.sin(X[:,5:6])\n",
    "  # if z=-1 -> fn1\n",
    "  un1 = np.exp(X[:,0:1]+X[:,1:2]+X[:,2:3]+X[:,3:4]+X[:,4:5]+X[:,5:6])\n",
    "  eu = u1*(z+1.0)/2.0 + un1*(1.0-z)/2.0\n",
    "  return eu\n",
    "\n",
    "def rhs_f(X_inner):\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  f1 = -6.0*np.sin(X_inner[:,0:1])*np.sin(X_inner[:,1:2])*np.sin(X_inner[:,2:3])*np.sin(X_inner[:,3:4])*np.sin(X_inner[:,4:5])*np.sin(X_inner[:,5:6])\n",
    "  # if z=-1 -> fn1\n",
    "  fn1 = 6.0*np.exp(X_inner[:,0:1]+X_inner[:,1:2]+X_inner[:,2:3]+X_inner[:,3:4]+X_inner[:,4:5]+X_inner[:,5:6])\n",
    "  rf = f1*(X_inner[:,6:7]+1.0)/2.0 + fn1*(1.0-X_inner[:,6:7])/2.0\n",
    "  return rf\n",
    "\n",
    "def normal_u(X):\n",
    "  x = X[:, 0:10]\n",
    "  z = X[:, 10]\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  u1 = (X[:,0]*X[:,1])*(X[:,0]**8 + X[:,1]**8) + (X[:,2]*X[:,3])*(X[:,2]**8 + X[:,3]**8) + X[:,4]*X[:,5]*(X[:,4]**8 + X[:,5]**8) + X[:,6]*X[:,7]*(X[:,6]**8 +X[:,7]**8) + X[:,8]*X[:,9]*(X[:,8]**8+X[:,9]**8)\n",
    "  u1 = u1/np.sqrt(x**2 + y**2)\n",
    "  # if z=-1 -> fn1\n",
    "  un1 = (x+y)*np.exp(x+y)\n",
    "  un1 = un1/np.sqrt(x**2 + y**2)\n",
    "  nu = u1*(z+1.0)/2.0 + un1*(1.0-z)/2.0\n",
    "  return nu\n",
    "\n",
    "def normal_u(x0, x1, x2, x3, x4, x5, z):\n",
    "  # exact_u = exact solution\n",
    "  # if z= 1 -> u1\n",
    "  u1 = np.cos(x0)*np.sin(x1)*np.sin(x2)*np.sin(x3)*np.sin(x4)*np.sin(x5)*x0\\\n",
    "  +np.sin(x0)*np.cos(x1)*np.sin(x2)*np.sin(x3)*np.sin(x4)*np.sin(x5)*x1\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.cos(x2)*np.sin(x3)*np.sin(x4)*np.sin(x5)*x2\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.sin(x2)*np.cos(x3)*np.sin(x4)*np.sin(x5)*x3\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.sin(x2)*np.sin(x3)*np.cos(x4)*np.sin(x5)*x4\\\n",
    "  +np.sin(x0)*np.sin(x1)*np.sin(x2)*np.sin(x3)*np.sin(x4)*np.cos(x5)*x5\n",
    "  dist = np.sqrt(x0**2 + x1**2 + x2**2+x3**2 + x4**2 + x5**2)\n",
    "  u1 = u1/dist\n",
    "  # if z=-1 -> fn1\n",
    "  un1 = (x0+x1+x2+x3+x4+x5)*np.exp(x0+x1+x2+x3+x4+x5)\n",
    "  un1 = un1/dist\n",
    "  nu = u1*(z+1.0)/2.0 + un1*(1.0-z)/2.0\n",
    "  return nu\n",
    "\n",
    "def sign_x(X):\n",
    "  z = 0.0*X[:,0:1] + 1.0\n",
    "  for i in range(len(z)):\n",
    "    dist = np.linalg.norm(X[i,:], 2)\n",
    "    if dist < 0.5:\n",
    "      z[i] = -1.0\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXmSiyPzRr-R",
    "outputId": "278316dc-4b69-48a3-fc27-e6c39a3f2024"
   },
   "outputs": [],
   "source": [
    "d = 6\n",
    "\n",
    "# number of grid points\n",
    "N_inner = 100\n",
    "N_bd = 141\n",
    "N_ij = 141\n",
    "\n",
    "# Training points\n",
    "\n",
    "## X_inner: points inside the domain, totally (N_inner-1)**2 points\n",
    "para_inner = lhs(d, N_inner)\n",
    "r = np.sqrt(para_inner[:,0:1]*0.36)\n",
    "t1 = para_inner[:,1:2]*np.pi\n",
    "t2 = para_inner[:,2:3]*np.pi\n",
    "t3 = para_inner[:,3:4]*np.pi\n",
    "t4 = para_inner[:,4:5]*np.pi\n",
    "t5 = para_inner[:,5:6]*2.0*np.pi\n",
    "X_inner = 0.0*para_inner\n",
    "X_inner[:, 0:1] = r*np.cos(t1)\n",
    "X_inner[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_inner[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_inner[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_inner[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_inner[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "z_inner = sign_x(X_inner)\n",
    "X_inner = np.hstack([X_inner, z_inner])\n",
    "Rf_inner = rhs_f(X_inner)\n",
    "Rf_inner = Rf_inner.reshape(N_inner, 1)\n",
    "\n",
    "## X_bd: points at the boundary, totally N_bd points\n",
    "para_bd = lhs(d, N_bd)\n",
    "r = 0.6\n",
    "t1 = para_bd[:,1:2]*np.pi\n",
    "t2 = para_bd[:,2:3]*np.pi\n",
    "t3 = para_bd[:,3:4]*np.pi\n",
    "t4 = para_bd[:,4:5]*np.pi\n",
    "t5 = para_bd[:,5:6]*2.0*np.pi\n",
    "X_bd = 0.0*para_bd\n",
    "X_bd[:, 0:1] = r*np.cos(t1)\n",
    "X_bd[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_bd[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_bd[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_bd[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_bd[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "X_bd = np.hstack([X_bd, 0.0*X_bd[:,0:1]+1.0])\n",
    "\n",
    "## U_bd: function values at the boundary, totally 2*d*N_bd points\n",
    "U_bd = exact_u(X_bd)\n",
    "U_bd = U_bd.reshape(N_bd, 1)\n",
    "\n",
    "## X_ij: points at the interior interface, totally N_ij points\n",
    "para_ij = lhs(d, N_bd)\n",
    "r = 0.5\n",
    "t1 = para_ij[:,1:2]*np.pi\n",
    "t2 = para_ij[:,2:3]*np.pi\n",
    "t3 = para_ij[:,3:4]*np.pi\n",
    "t4 = para_ij[:,4:5]*np.pi\n",
    "t5 = para_ij[:,5:6]*2.0*np.pi\n",
    "X_ij = 0.0*para_ij\n",
    "X_ij[:, 0:1] = r*np.cos(t1)\n",
    "X_ij[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_ij[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_ij[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_ij[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_ij[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "\n",
    "## Uj_ij: function jump at the interior interface, totally 2*d*N_bd points\n",
    "Uj_ij = exact_u(np.hstack([X_ij, 0.0*X_ij[:,0:1]+1.0])) - exact_u(np.hstack([X_ij, 0.0*X_ij[:,0:1]-1.0]))\n",
    "Uj_ij = Uj_ij.reshape(N_ij, 1)\n",
    "\n",
    "# beta_plus\n",
    "beta_plus = 1.0e-3\n",
    "## Unj_ij: normal jump at the interior interface, totally N_bd points\n",
    "Unj_ij = beta_plus*normal_u(X_ij[:,0:1], X_ij[:,1:2], X_ij[:,2:3], X_ij[:,3:4], X_ij[:,4:5], X_ij[:,5:6], 0.0*X_ij[:,0:1]+1.0)\\\n",
    "- normal_u(X_ij[:,0:1], X_ij[:,1:2], X_ij[:,2:3], X_ij[:,3:4], X_ij[:,4:5], X_ij[:,5:6], 0.0*X_ij[:,0:1]-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain(\n",
      "  (ln1): Linear(in_features=7, out_features=10, bias=True)\n",
      "  (act1): Sigmoid()\n",
      "  (ln2): Linear(in_features=10, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# single-layer model\n",
    "model = Plain(7, 10, 1).to(device)\n",
    "print(model)\n",
    "\n",
    "# Make model a functional\n",
    "func_model, func_params = make_functional(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bd = torch.from_numpy(X_bd).requires_grad_(True).double().to(device)\n",
    "U_bd = torch.from_numpy(U_bd).double().to(device)\n",
    "X_inner = torch.from_numpy(X_inner).requires_grad_(True).double().to(device)\n",
    "Rf_inner = torch.from_numpy(Rf_inner).double().to(device)\n",
    "X_ij = torch.from_numpy(X_ij).requires_grad_(True).double().to(device)\n",
    "Uj_ij = torch.from_numpy(Uj_ij).double().to(device)\n",
    "Unj_ij = torch.from_numpy(Unj_ij).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aChmjTLTRsNt",
    "outputId": "385c417f-97dc-4b20-b21a-109611035f2c"
   },
   "outputs": [],
   "source": [
    "LM_iter = 2000\n",
    "mu_update = 2 # update \\mu every mu_update iterations\n",
    "div_factor = 1.3 # \\mu <- \\mu/div_factor when loss decreases\n",
    "mul_factor = 3 # \\mu <- mul_factor*\\mu when loss incerases\n",
    "\n",
    "mu = 10**5\n",
    "loss_sum_old = 10**5\n",
    "itera = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "id": "2W4aJaHjwUKd",
    "outputId": "e06087e0-0b22-4fdd-a789-06442a3b1a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1, Loss_Res: 3.49630e+01, mu: 7.69231e+04\n",
      "Iter 101, Loss_Res: 4.39588e-01, mu: 1.54486e-01\n",
      "Iter 201, Loss_Res: 7.35093e-06, mu: 1.21000e-06\n",
      "Iter 301, Loss_Res: 1.36939e-08, mu: 1.30057e-07\n",
      "Iter 401, Loss_Res: 1.32618e-09, mu: 2.12625e-07\n",
      "Iter 501, Loss_Res: 1.02072e-09, mu: 3.47610e-07\n",
      "Iter 601, Loss_Res: 9.65863e-10, mu: 5.68291e-07\n",
      "Iter 701, Loss_Res: 9.29999e-10, mu: 2.38223e-07\n",
      "Iter 801, Loss_Res: 8.96700e-10, mu: 3.89460e-07\n",
      "Iter 901, Loss_Res: 8.62399e-10, mu: 1.63259e-07\n",
      "Iter 1001, Loss_Res: 8.46342e-10, mu: 2.66904e-07\n",
      "Iter 1101, Loss_Res: 8.35061e-10, mu: 1.11884e-07\n",
      "Iter 1201, Loss_Res: 8.25085e-10, mu: 1.82914e-07\n",
      "Iter 1301, Loss_Res: 8.14876e-10, mu: 7.66763e-08\n",
      "Iter 1401, Loss_Res: 8.06515e-10, mu: 1.25354e-07\n",
      "Iter 1501, Loss_Res: 7.98150e-10, mu: 5.25477e-08\n",
      "Iter 1601, Loss_Res: 7.92533e-10, mu: 8.59077e-08\n",
      "Iter 1701, Loss_Res: 7.88684e-10, mu: 1.40446e-07\n",
      "Iter 1801, Loss_Res: 7.85644e-10, mu: 2.29609e-07\n",
      "Iter 1901, Loss_Res: 7.83041e-10, mu: 9.62505e-08\n",
      "Iter 2001, Loss_Res: 7.80763e-10, mu: 1.57355e-07\n",
      "CPU times: user 1min 21s, sys: 1min 44s, total: 3min 5s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for step in range(LM_iter+1):\n",
    "    # Put into loss functional to get L_vec\n",
    "    L_vec_res = vmap(compute_loss_Res, (None, 0, 0))(func_params, X_inner, Rf_inner)\n",
    "    L_vec_b = vmap(compute_loss_b, (None, 0, 0))(func_params, X_bd, U_bd)\n",
    "    L_vec_j = vmap(compute_loss_j, (None, 0, 0))(func_params, X_ij, Uj_ij)\n",
    "    L_vec_nj = vmap(compute_loss_normal_jump, (None, 0, 0))(func_params, X_ij, Unj_ij)\n",
    "\n",
    "    L_vec_res = L_vec_res/np.sqrt(N_inner)\n",
    "    L_vec_b = L_vec_b/np.sqrt(N_bd)\n",
    "    L_vec_j = L_vec_j/np.sqrt(N_ij)\n",
    "    L_vec_nj = L_vec_nj/np.sqrt(N_ij)\n",
    "    loss = torch.sum(L_vec_res**2) + torch.sum(L_vec_b**2) + torch.sum(L_vec_j**2) + torch.sum(L_vec_nj**2)\n",
    "\n",
    "    # Consturct J for domain points\n",
    "    # (None, 0 ,0): func_params: no batch. data_d: batch wrt shape[0] (data[i, :]). force_value: batch wrt shape[0] (force_value[i,:])\n",
    "    \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_Res), (None, 0, 0))(func_params, X_inner, Rf_inner)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_res = g.view(len(g), -1) if cnt == 0 else torch.hstack([J_d_res, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "    \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_b), (None, 0, 0))(func_params, X_bd, U_bd)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_b = g.view(len(g), -1) if cnt == 0 else torch.hstack([J_d_b, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "        \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_j), (None, 0, 0))(func_params, X_ij, Uj_ij)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_j = g.view(len(g), -1) if cnt == 0 else torch.hstack([J_d_j, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "        \n",
    "    per_sample_grads = vmap(jacrev(compute_loss_normal_jump), (None, 0, 0))(func_params, X_ij, Unj_ij)\n",
    "    cnt = 0\n",
    "    for g in per_sample_grads: \n",
    "        g = g.detach()\n",
    "        J_d_nj = g.contiguous().view(len(g), -1) if cnt == 0 else torch.hstack([J_d_nj, g.view(len(g), -1)])\n",
    "        cnt = 1\n",
    "\n",
    "    # cat J_d and J_b into J\n",
    "    J_mat = torch.cat((J_d_res, J_d_b, J_d_j, J_d_nj))\n",
    "    L_vec = torch.cat((L_vec_res, L_vec_b, L_vec_j, L_vec_nj))\n",
    "\n",
    "    # update lambda\n",
    "    I = torch.eye((J_mat.shape[1])).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        J_product = J_mat.t()@J_mat\n",
    "        rhs = -J_mat.t()@L_vec\n",
    "        with torch.no_grad():\n",
    "            dp = torch.linalg.solve(J_product + mu*I, rhs)\n",
    "\n",
    "        # update parameters\n",
    "        cnt=0\n",
    "        for p in func_params:\n",
    "            mm=torch.Tensor([p.shape]).tolist()[0]\n",
    "            num=int(functools.reduce(lambda x,y:x*y,mm,1))\n",
    "            p+=dp[cnt:cnt+num].reshape(p.shape)\n",
    "            cnt+=num\n",
    "\n",
    "        itera += 1\n",
    "        if step % mu_update == 0:\n",
    "            #if loss_sum_check < loss_sum_old:\n",
    "            if loss < loss_sum_old:\n",
    "                mu = max(mu/div_factor, 10**(-9))\n",
    "            else:\n",
    "                mu = min(mul_factor*mu, 10**(8))\n",
    "            loss_sum_old = loss\n",
    "                \n",
    "        if step%100 == 0:\n",
    "            print(\n",
    "                    'Iter %d, Loss_Res: %.5e, mu: %.5e' % (itera, loss.item(), mu)\n",
    "                )\n",
    "            \n",
    "        if step == LM_iter or loss.item()<10**(-12):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQTHAR0ARsQN",
    "outputId": "3f07fa0b-7388-4eb4-acd0-2308c080d7c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error u (absolute inf-norm): 1.808054e-04\n",
      "Error u (absolute 2-norm): 7.594053e-06\n"
     ]
    }
   ],
   "source": [
    "N_test = 200000\n",
    "\n",
    "para_test = lhs(d, N_test)\n",
    "r = np.sqrt(para_test[:,0:1]*0.36)\n",
    "t1 = para_test[:,1:2]*np.pi\n",
    "t2 = para_test[:,2:3]*np.pi\n",
    "t3 = para_test[:,3:4]*np.pi\n",
    "t4 = para_test[:,4:5]*np.pi\n",
    "t5 = para_test[:,5:6]*2.0*np.pi\n",
    "X_test = 0.0*para_test\n",
    "X_test[:, 0:1] = r*np.cos(t1)\n",
    "X_test[:, 1:2] = r*np.sin(t1)*np.cos(t2)\n",
    "X_test[:, 2:3] = r*np.sin(t1)*np.sin(t2)*np.cos(t3)\n",
    "X_test[:, 3:4] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.cos(t4)\n",
    "X_test[:, 4:5] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.cos(t5)\n",
    "X_test[:, 5:6] = r*np.sin(t1)*np.sin(t2)*np.sin(t3)*np.sin(t4)*np.sin(t5)\n",
    "z_test = sign_x(X_test)\n",
    "X_test = np.hstack([X_test, z_test])\n",
    "\n",
    "Exact_test = exact_u(X_test)\n",
    "Exact_test = Exact_test.reshape((N_test,1))\n",
    "\n",
    "X_test_torch = torch.tensor(X_test).double().to(device)\n",
    "u_pred = func_model(func_params, X_test_torch).detach().cpu().numpy()\n",
    "\n",
    "error = np.absolute(u_pred - Exact_test)\n",
    "\n",
    "error_u_inf = np.linalg.norm(error, np.inf)\n",
    "print('Error u (absolute inf-norm): %e' % (error_u_inf))\n",
    "error_u_2 = np.linalg.norm(error,2)/np.sqrt(N_test)\n",
    "print('Error u (absolute 2-norm): %e' % (error_u_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SINet_poisson_6D_sphe_sphe_double.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
